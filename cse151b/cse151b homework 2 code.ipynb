{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "\n",
    "def pool2d(A, kernel_size, stride, padding=0, pool_mode='max'):\n",
    "    '''\n",
    "    2D Pooling\n",
    "\n",
    "    Parameters:\n",
    "        A: input 2D array\n",
    "        kernel_size: int, the size of the window over which we take pool\n",
    "        stride: int, the stride of the window\n",
    "        padding: int, implicit zero paddings on both sides of the input\n",
    "        pool_mode: string, 'max' or 'avg'\n",
    "    '''\n",
    "    # Padding\n",
    "    A = np.pad(A, padding, mode='constant')\n",
    "\n",
    "    # Window view of A\n",
    "    output_shape = ((A.shape[0] - kernel_size) // stride + 1,\n",
    "                    (A.shape[1] - kernel_size) // stride + 1)\n",
    "    \n",
    "    shape_w = (output_shape[0], output_shape[1], kernel_size, kernel_size)\n",
    "    strides_w = (stride*A.strides[0], stride*A.strides[1], A.strides[0], A.strides[1])\n",
    "    \n",
    "    A_w = as_strided(A, shape_w, strides_w)\n",
    "\n",
    "    # Return the result of pooling\n",
    "    if pool_mode == 'max':\n",
    "        return A_w.max(axis=(2, 3))\n",
    "    elif pool_mode == 'avg':\n",
    "        return A_w.mean(axis=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 =    np.array([[1, 1, 1, 0],\n",
    "                  [1, 1, 1, 0],\n",
    "                  [1, 1, 1, 0],\n",
    "                  [0, 0, 0, 0]])\n",
    "\n",
    "A2 =    np.array([[0, 1, 1, 1],\n",
    "                  [0, 1, 1, 1],\n",
    "                  [0, 1, 1, 1],\n",
    "                  [0, 0, 0, 0]])\n",
    "\n",
    "A3 =    np.array([[0, 0, 0, 0],\n",
    "                  [0, 1, 1, 1],\n",
    "                  [0, 1, 1, 1],\n",
    "                  [0, 1, 1, 1]])\n",
    "\n",
    "A4 =    np.array([[0, 0, 0, 0],\n",
    "                  [1, 1, 1, 0],\n",
    "                  [1, 1, 1, 0],\n",
    "                  [1, 1, 1, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(A3, 2, 2, padding=0, pool_mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c70b3d3d7c34ff9b586c3d6f0109792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dede5362ca11465a873a46057b1a85c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9ce697d7e6447f9364349e09482222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c972ca5d85204c60a7a058838415581f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((28,28)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "train_data = datasets.MNIST(root='./data_1', train=True, download=True, transform=transform)\n",
    "val_data = datasets.MNIST(root='./data_1', train=False, download=True, transform=transform)\n",
    "\n",
    "train_load = torch.utils.data.DataLoader(train_data, batch_size= 100, shuffle=True)\n",
    "val_load = torch.utils.data.DataLoader(val_data, batch_size = 100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1) \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1) \n",
    "        # self.conv3 = nn.Conv2d(20, 50, 5, 1) \n",
    "        self.fc1 = nn.Linear(4*4*50, 500)   \n",
    "        self.dropout1 = nn.Dropout(0.5)  \n",
    "        self.fc2 = nn.Linear(500, 10)   \n",
    "        #self.dropout2 = nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) \n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        #x = F.avg_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv2(x)) \n",
    "        x = F.max_pool2d(x, 2, 2) \n",
    "        #x = F.avg_pool2d(x,2,2)\n",
    "        x = x.view(-1, 4*4*50)    \n",
    "        x = F.relu(self.fc1(x))  \n",
    "        #x = F.sigmoid(self.fc1(x))\n",
    "        x = self.dropout1(x)    \n",
    "        x = self.fc2(x)       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(dev)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-1.7541e-01,  1.6635e-01,  1.1223e-01,  1.9127e-01, -1.3575e-02],\n",
      "          [ 1.6344e-01,  1.0488e-01, -3.2710e-02,  1.7194e-01, -9.6758e-02],\n",
      "          [-1.5840e-01, -6.0319e-02,  3.2582e-02,  5.4971e-02, -1.1705e-01],\n",
      "          [ 1.4611e-01,  1.3021e-01, -1.8298e-01, -2.8990e-02,  1.7725e-01],\n",
      "          [ 1.1592e-01, -1.1321e-02,  1.6383e-02, -9.7256e-02, -1.9391e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.7894e-02,  8.5141e-02, -1.1301e-01, -4.5816e-02, -4.6910e-02],\n",
      "          [ 1.1667e-01, -1.5140e-01, -1.0361e-01,  6.7587e-02, -1.9874e-01],\n",
      "          [ 6.2912e-03,  8.4149e-02,  1.2521e-01, -1.2650e-01, -1.2585e-01],\n",
      "          [ 1.1424e-01,  6.3949e-02, -3.7853e-03,  8.5108e-02,  4.2463e-02],\n",
      "          [-1.5692e-01, -1.3373e-01,  1.4296e-01,  1.6755e-01,  6.6007e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3358e-01,  1.9661e-01, -5.1712e-02, -1.1313e-01,  6.5649e-03],\n",
      "          [ 1.7667e-01,  1.8840e-01,  2.3272e-02,  4.5110e-02,  7.5204e-02],\n",
      "          [ 1.8057e-02, -6.6447e-02, -1.8509e-01, -3.1900e-02,  1.8263e-01],\n",
      "          [-1.0111e-01, -1.1952e-01,  1.9134e-01, -1.2646e-01, -1.5482e-01],\n",
      "          [ 1.5687e-01, -1.7888e-01,  1.6448e-02, -1.1718e-01, -1.6593e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4601e-01, -3.1365e-03,  1.4879e-01,  1.4650e-01,  1.8431e-01],\n",
      "          [-1.2612e-01, -1.1463e-01,  1.1130e-01,  1.5987e-02,  4.5413e-02],\n",
      "          [-5.2170e-02, -1.7792e-01,  3.8019e-02,  1.3887e-01, -3.9854e-02],\n",
      "          [-1.2887e-02,  9.8682e-02,  1.8205e-01, -1.1864e-01,  9.6122e-02],\n",
      "          [ 1.3433e-01, -1.5364e-01, -1.6016e-01,  1.9748e-01,  9.1347e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8560e-01,  1.4631e-01,  1.6847e-01,  9.1520e-03,  1.9578e-01],\n",
      "          [-8.1500e-03,  1.9835e-01, -1.7280e-01, -9.4320e-02,  1.5598e-01],\n",
      "          [ 1.6898e-01, -1.6009e-01,  1.2483e-01,  3.8044e-02,  1.9796e-01],\n",
      "          [-7.1574e-02,  6.9118e-02,  1.7813e-01,  1.5108e-01,  8.1075e-02],\n",
      "          [-1.5362e-01, -1.6372e-02,  1.1055e-01, -4.9317e-02, -1.1343e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.1366e-02,  1.4751e-01,  4.8266e-02,  1.8389e-01, -4.0468e-02],\n",
      "          [-1.2400e-01,  9.9959e-02,  8.2979e-02, -4.6214e-02, -1.7276e-02],\n",
      "          [-2.0705e-02,  1.8581e-01,  1.4004e-01, -5.3596e-02, -1.7812e-01],\n",
      "          [-1.4612e-01,  5.9000e-02,  1.5793e-01, -7.2865e-02,  4.0872e-02],\n",
      "          [ 2.8470e-02, -8.8405e-02, -8.9268e-02, -1.1805e-01, -4.0358e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7234e-02, -2.4881e-02, -1.4345e-01, -1.2564e-01, -1.8147e-01],\n",
      "          [ 1.8178e-01, -8.8408e-02, -1.3731e-01,  7.2433e-02, -1.5842e-01],\n",
      "          [ 1.4952e-01,  9.5602e-02,  1.9089e-01,  6.5989e-02, -1.3552e-01],\n",
      "          [ 3.4920e-02,  1.8172e-01,  7.8571e-02,  1.8567e-01,  1.2456e-01],\n",
      "          [ 1.4744e-01,  5.2407e-05,  1.1396e-01,  1.4678e-01,  1.2780e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5798e-01, -1.6064e-01,  5.3309e-02,  1.0434e-01, -7.0675e-02],\n",
      "          [-6.4375e-02, -1.2402e-01, -1.0697e-01,  7.5542e-02, -1.2136e-01],\n",
      "          [-1.6243e-01, -1.9301e-01,  1.5837e-01,  3.5098e-02, -1.8893e-01],\n",
      "          [-1.8362e-01, -7.1762e-02,  6.1140e-03, -1.0271e-01,  9.0999e-02],\n",
      "          [ 1.9138e-01, -7.4276e-04,  8.1674e-02, -5.8005e-03,  7.5991e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0830e-02,  1.9339e-01, -5.3149e-02,  9.8241e-02,  3.4098e-02],\n",
      "          [ 1.8752e-01,  1.9946e-01, -1.7645e-01, -8.2005e-02,  1.1890e-01],\n",
      "          [-1.7796e-01, -1.5588e-02, -7.4939e-02, -9.3555e-02, -1.6108e-01],\n",
      "          [-1.3735e-01,  1.8102e-01,  8.6983e-02, -1.6938e-01, -8.3613e-02],\n",
      "          [ 1.6705e-02,  1.0638e-01,  1.8660e-01,  8.2082e-02,  1.0623e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0888e-02,  6.7076e-02,  1.6956e-01,  1.2752e-01,  2.2509e-02],\n",
      "          [-9.2027e-02, -1.3764e-01, -1.9396e-01, -8.6958e-03, -8.9471e-02],\n",
      "          [ 2.6427e-02,  1.9297e-01, -1.7701e-01, -1.0990e-01,  1.4487e-01],\n",
      "          [-2.3256e-02, -1.7380e-02,  2.4711e-02, -2.6765e-02, -8.2888e-02],\n",
      "          [ 1.4155e-01, -2.5123e-02, -2.2549e-02, -5.7688e-02,  8.5211e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9854e-02, -9.7857e-02,  8.3320e-02,  6.9677e-02, -1.3732e-01],\n",
      "          [ 1.8721e-01, -1.3315e-01, -9.1931e-02, -1.5177e-02,  8.0034e-02],\n",
      "          [ 6.4081e-02, -1.4179e-02, -1.0122e-01,  7.6257e-03, -1.4602e-01],\n",
      "          [ 9.6275e-02, -8.2868e-02, -1.8506e-01, -1.3918e-01, -1.8498e-01],\n",
      "          [ 9.6140e-02,  8.2029e-02,  1.4559e-03, -1.6355e-01, -1.8301e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.9286e-02, -1.1514e-03,  8.6238e-02,  3.0557e-02, -1.5492e-01],\n",
      "          [-1.6961e-01,  1.7164e-01,  1.4717e-01, -1.7271e-01,  1.2664e-01],\n",
      "          [ 7.7226e-02,  1.9101e-01, -5.6683e-03,  5.2629e-02,  1.8320e-01],\n",
      "          [ 8.1665e-03,  8.9389e-02,  1.8496e-01,  3.2195e-02,  1.3135e-01],\n",
      "          [-1.7831e-01,  7.0588e-02,  9.4157e-02, -1.6503e-01, -4.1200e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2423e-01,  1.8959e-01, -1.3654e-03, -8.9342e-02,  1.5175e-01],\n",
      "          [ 1.1496e-01, -4.6115e-03,  1.8461e-01, -1.8008e-01,  5.2214e-02],\n",
      "          [ 1.2635e-01,  1.9206e-01, -6.5076e-02,  1.4233e-01,  5.0965e-02],\n",
      "          [ 1.7666e-01, -1.3407e-02, -1.6803e-01,  1.3885e-01,  6.1148e-02],\n",
      "          [-1.5086e-01, -3.1454e-02,  1.7252e-02, -8.9610e-02, -5.3328e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8022e-03, -1.1674e-01, -1.1406e-01,  1.6474e-01, -4.6840e-02],\n",
      "          [-1.7539e-01,  1.4571e-01,  5.0276e-02,  1.6437e-01, -3.5534e-02],\n",
      "          [ 1.6375e-03,  4.9099e-02, -5.2989e-02, -3.5648e-02,  7.4676e-02],\n",
      "          [-1.8288e-01,  1.7501e-01, -1.5638e-01, -1.7365e-01, -1.0426e-01],\n",
      "          [-1.9924e-01, -1.7650e-01, -4.7805e-03,  1.8669e-02,  1.3581e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1529e-01, -3.3466e-02, -7.4388e-02, -1.8575e-01, -3.6455e-02],\n",
      "          [ 3.4128e-03, -9.3440e-02,  5.9253e-02, -8.4992e-02, -1.5413e-01],\n",
      "          [ 4.1340e-02,  5.5863e-02, -1.5443e-01,  4.3434e-02, -4.8596e-02],\n",
      "          [-5.9831e-02, -1.5271e-01,  1.4302e-01, -7.4004e-02, -1.5616e-01],\n",
      "          [-1.1456e-01,  2.1180e-02,  1.0317e-01, -1.2805e-01,  1.8178e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3744e-02, -1.3967e-01, -9.9645e-02, -8.0977e-02, -1.3370e-01],\n",
      "          [ 3.6351e-02, -1.8011e-01, -1.5366e-02, -7.1682e-03,  1.9027e-01],\n",
      "          [-4.9803e-02, -1.5006e-01,  5.4425e-02,  4.6427e-02, -1.0116e-01],\n",
      "          [ 1.6491e-01,  1.0821e-01, -3.0785e-02,  1.6543e-02,  1.6526e-01],\n",
      "          [ 7.0587e-02, -5.7600e-02,  1.3283e-01,  3.4488e-02,  1.3065e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.9356e-02,  1.1643e-01,  1.4018e-01, -9.7643e-02,  2.8590e-02],\n",
      "          [-1.4067e-01, -2.5920e-02,  7.8830e-02,  1.8191e-01,  8.6113e-02],\n",
      "          [-2.4227e-03, -9.0594e-02, -1.0727e-01,  1.0147e-01,  6.2682e-02],\n",
      "          [ 1.0333e-01,  1.8969e-02,  3.4828e-02, -4.1224e-03, -2.8390e-02],\n",
      "          [-1.7986e-01,  9.6859e-02, -1.0898e-01, -6.3925e-02,  5.2884e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3799e-01, -1.1592e-01,  1.9366e-01,  4.8059e-02, -1.2553e-01],\n",
      "          [ 1.4003e-01, -1.8656e-01,  1.5560e-01, -2.5393e-03, -1.0008e-01],\n",
      "          [-4.2628e-02, -1.6681e-01, -1.8243e-01,  1.9368e-01,  1.9826e-01],\n",
      "          [-1.7809e-01,  9.4974e-02, -1.0911e-01, -1.6811e-01, -1.0705e-01],\n",
      "          [ 8.0039e-02, -2.6175e-02,  1.4031e-01, -3.8901e-02,  4.9725e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2196e-01, -7.3646e-02,  5.7463e-02,  1.6285e-01,  1.6202e-01],\n",
      "          [ 3.1512e-02,  6.3143e-02,  1.0342e-01,  3.9062e-02, -1.2573e-01],\n",
      "          [-1.5875e-01,  1.9949e-02,  1.0886e-01, -1.3627e-01,  1.7403e-02],\n",
      "          [-3.6154e-02, -1.9399e-01,  1.3009e-02,  1.0748e-01, -2.3003e-02],\n",
      "          [ 1.9569e-01, -1.3312e-02, -4.5329e-02,  1.3029e-01,  4.0848e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4790e-01, -1.6946e-03, -2.6516e-02,  2.0313e-02, -5.4758e-02],\n",
      "          [ 8.4714e-02,  4.1789e-03, -2.5803e-02, -1.5152e-01,  9.0597e-02],\n",
      "          [-1.8530e-01,  6.4161e-02,  1.6178e-01, -1.0840e-01, -1.3097e-01],\n",
      "          [-1.3128e-01,  1.9547e-01,  1.3307e-01,  7.0622e-02,  1.5330e-02],\n",
      "          [ 7.4370e-02,  1.5623e-01, -1.6659e-01, -1.8078e-01, -1.0546e-01]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0302, -0.1420, -0.1494,  0.1881, -0.1538, -0.0178, -0.0620,  0.1187,\n",
      "         0.1607,  0.1868,  0.1436,  0.1894, -0.0507,  0.1296, -0.1271, -0.1242,\n",
      "         0.1762, -0.0627,  0.1483,  0.1398], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 1.0424e-02, -2.4608e-03, -1.0358e-02, -3.2703e-02,  6.1723e-03],\n",
      "          [ 7.1698e-03,  2.0986e-02, -3.3347e-02,  2.5133e-02, -4.4954e-03],\n",
      "          [ 1.0358e-02, -2.6198e-02, -1.5482e-02,  2.8375e-02,  2.4843e-02],\n",
      "          [ 3.9916e-02,  4.2813e-02, -7.9742e-03, -3.3340e-02,  3.2392e-02],\n",
      "          [-3.8294e-02,  3.4446e-02, -7.9647e-03, -3.9557e-02,  3.2652e-02]],\n",
      "\n",
      "         [[ 2.1861e-02, -4.4140e-02, -9.4018e-03,  5.9186e-04, -1.7591e-02],\n",
      "          [ 2.1396e-04, -2.1549e-02,  2.7015e-02, -3.6210e-02, -3.8675e-02],\n",
      "          [-2.8784e-02,  3.6900e-03,  1.4812e-02,  2.3160e-02,  3.8115e-02],\n",
      "          [ 6.8194e-03, -2.2695e-02, -4.2952e-02,  3.9865e-02, -3.7178e-02],\n",
      "          [ 4.3381e-02,  1.6654e-02,  6.9823e-03, -4.0724e-02,  1.6415e-02]],\n",
      "\n",
      "         [[ 2.2531e-02, -2.6630e-02,  3.7972e-02,  2.5047e-02, -1.7366e-02],\n",
      "          [ 2.2809e-02,  7.5480e-03,  3.2638e-02, -1.4803e-02, -1.1642e-02],\n",
      "          [ 2.6236e-02,  3.0042e-02,  3.0926e-02,  3.0027e-02,  4.0136e-02],\n",
      "          [ 2.5656e-02, -2.4495e-02,  3.0468e-02, -1.0136e-02, -1.3896e-02],\n",
      "          [ 3.6282e-02, -1.0215e-02, -1.5742e-02,  2.2927e-02,  4.3645e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.3851e-04, -1.0957e-02,  2.7525e-02,  9.0278e-03,  2.0786e-02],\n",
      "          [-1.6826e-02,  2.2451e-02,  3.1926e-02,  1.8198e-02, -1.9600e-02],\n",
      "          [-3.5737e-02, -1.7119e-02, -2.2879e-02, -3.8974e-02,  2.7270e-02],\n",
      "          [-1.6792e-02,  1.9283e-02, -1.9652e-02,  1.4646e-02,  9.9995e-03],\n",
      "          [ 3.5462e-02, -2.8915e-02,  7.0519e-03,  2.8326e-02,  3.0366e-02]],\n",
      "\n",
      "         [[-4.4609e-02,  1.5551e-02, -6.7355e-03,  4.2739e-02,  9.9961e-04],\n",
      "          [ 8.3768e-03,  1.9732e-02, -3.3572e-02, -4.1970e-02,  2.7946e-04],\n",
      "          [ 1.8718e-02,  3.0225e-02, -8.3276e-03, -4.3452e-02,  1.0791e-02],\n",
      "          [-8.9291e-04,  3.4709e-02,  2.7776e-02,  1.5534e-02, -1.2181e-02],\n",
      "          [-2.2736e-02, -6.2124e-03,  3.9987e-02, -7.6923e-03,  1.0128e-02]],\n",
      "\n",
      "         [[-3.4494e-02, -3.9734e-03,  7.0921e-04, -6.2386e-04, -1.1740e-02],\n",
      "          [ 1.3380e-02,  3.2383e-02, -4.4529e-02, -3.0450e-02, -1.8563e-02],\n",
      "          [-4.8988e-03, -1.8337e-02,  2.6966e-03, -4.0674e-02, -3.4196e-02],\n",
      "          [ 4.4107e-03,  1.5312e-02, -1.6381e-02, -3.7495e-02, -3.0905e-02],\n",
      "          [-3.9179e-02,  5.4877e-03,  3.1626e-03,  3.1100e-02, -5.0353e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1070e-02, -4.4549e-02, -2.1421e-02, -1.6505e-04, -4.2411e-02],\n",
      "          [ 2.7258e-02,  9.1218e-03, -3.6677e-03,  2.3439e-02,  5.9868e-03],\n",
      "          [-2.3409e-03,  3.5401e-02, -2.6542e-02, -2.2455e-02, -1.1297e-02],\n",
      "          [-1.7484e-02,  1.8891e-02, -3.6552e-02,  1.7557e-02, -9.1339e-03],\n",
      "          [-3.4867e-02, -3.0598e-02,  3.7190e-02,  2.6489e-02, -1.9360e-02]],\n",
      "\n",
      "         [[-1.3823e-02,  3.8688e-02, -4.0311e-02,  5.3296e-03,  3.5224e-02],\n",
      "          [ 2.9703e-02,  1.8358e-02, -2.5693e-02,  8.0005e-03, -2.2865e-04],\n",
      "          [ 1.3822e-02, -3.8692e-02,  3.1641e-02, -1.5327e-02, -3.2963e-02],\n",
      "          [-2.3842e-02, -3.1548e-02,  3.7641e-02, -4.4693e-02,  3.9829e-02],\n",
      "          [ 3.0829e-02, -3.9948e-02,  1.4365e-02,  1.5890e-02,  1.2282e-03]],\n",
      "\n",
      "         [[-9.9399e-03, -2.9396e-02,  3.9828e-03,  3.4142e-02,  3.6417e-02],\n",
      "          [-1.1244e-02,  1.2136e-03,  2.6217e-02,  2.9517e-02, -1.9098e-02],\n",
      "          [-6.1675e-03, -8.7811e-03,  2.0455e-02,  4.0591e-03,  1.0574e-02],\n",
      "          [-4.0717e-02,  5.1193e-03, -2.3268e-02,  4.3100e-02, -5.8982e-03],\n",
      "          [ 3.2930e-02,  3.2429e-02,  1.9537e-02, -5.7709e-03, -3.9992e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6525e-02, -1.3156e-02,  1.8239e-02, -1.4666e-02, -3.9303e-02],\n",
      "          [-3.0496e-02, -2.3366e-02, -3.5312e-02, -3.3109e-02, -1.8451e-02],\n",
      "          [ 1.8349e-02,  2.5052e-02,  2.1967e-02,  1.2822e-02, -2.1482e-02],\n",
      "          [-2.3223e-02, -4.2723e-02,  1.7611e-02, -9.3641e-03,  1.8572e-02],\n",
      "          [-2.9928e-02,  3.9783e-02, -2.3650e-02,  3.8082e-02,  2.3484e-02]],\n",
      "\n",
      "         [[ 4.0727e-02, -2.8681e-02, -4.6509e-03, -1.8462e-02,  4.2187e-02],\n",
      "          [ 1.4096e-03, -1.2109e-02,  4.2689e-02,  8.1248e-03,  2.8181e-02],\n",
      "          [ 2.8304e-02, -1.6374e-02,  4.3805e-02, -2.1481e-02,  3.0159e-03],\n",
      "          [ 1.3523e-02, -3.8295e-02,  3.5737e-02, -3.2351e-03,  2.7197e-02],\n",
      "          [-4.8392e-03, -4.1715e-02,  3.1339e-02,  2.2994e-02,  1.0741e-02]],\n",
      "\n",
      "         [[-3.7242e-03,  1.8830e-02, -8.6975e-03,  1.0891e-02, -1.2321e-02],\n",
      "          [ 6.6447e-03, -1.9028e-02,  2.4887e-02, -2.3016e-02, -1.1081e-02],\n",
      "          [ 2.3538e-02,  2.7047e-02, -8.8575e-03, -2.7602e-02, -2.0634e-03],\n",
      "          [ 2.1965e-02,  2.7751e-02, -3.9467e-02,  7.4634e-03,  5.4756e-03],\n",
      "          [-6.6140e-03, -2.1630e-03,  9.7104e-03,  1.3808e-02, -1.4136e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1473e-02,  1.4258e-02, -1.2284e-02, -1.9843e-02,  3.6459e-02],\n",
      "          [-2.1925e-02,  2.9823e-02, -2.0702e-02, -3.7045e-02,  2.8841e-03],\n",
      "          [-3.7273e-02,  4.2272e-02,  2.1179e-03,  4.1915e-02, -8.8425e-03],\n",
      "          [-1.7926e-02,  1.8226e-02,  3.0295e-02,  6.2110e-03,  5.0171e-03],\n",
      "          [-2.3589e-02,  1.1557e-03, -2.8514e-02,  6.4114e-03,  4.2672e-02]],\n",
      "\n",
      "         [[ 1.6584e-02, -2.9846e-02,  1.4705e-02, -3.5424e-02, -2.0171e-03],\n",
      "          [ 7.8645e-03, -3.0398e-02, -2.5778e-02,  3.3641e-02, -4.3877e-03],\n",
      "          [ 1.2721e-02, -4.2023e-02, -2.2811e-03,  3.0508e-02, -1.9820e-02],\n",
      "          [ 2.6953e-02,  3.5473e-02,  9.5813e-03, -2.8339e-02,  3.8113e-02],\n",
      "          [ 6.7036e-03, -7.0230e-03,  8.2019e-03, -2.7595e-02,  4.8038e-03]],\n",
      "\n",
      "         [[-2.9154e-02, -3.1082e-02, -2.2806e-03, -1.8519e-02, -3.3154e-02],\n",
      "          [ 2.4446e-02, -2.3705e-02, -3.3530e-03, -3.2620e-02, -1.5408e-03],\n",
      "          [ 1.0232e-03, -3.3539e-02, -1.4127e-02, -3.8822e-02,  4.1242e-02],\n",
      "          [-3.2425e-02, -4.1854e-02, -4.1727e-02,  3.1973e-02,  2.2023e-02],\n",
      "          [-3.0747e-02, -3.9514e-02, -9.4499e-03, -1.6610e-02,  6.5118e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8599e-02,  9.7161e-03,  2.6122e-03,  1.0766e-02, -3.0004e-02],\n",
      "          [-1.6719e-02, -2.4187e-02,  1.7396e-02,  2.3222e-02,  1.8257e-02],\n",
      "          [ 3.8555e-02,  2.1404e-02, -6.0682e-03, -4.3656e-02,  2.5937e-02],\n",
      "          [-3.3070e-02,  4.0418e-02,  4.0217e-02, -1.3293e-02, -3.5162e-02],\n",
      "          [-3.5073e-03, -1.8540e-02, -2.6714e-02,  3.8770e-02, -1.4397e-02]],\n",
      "\n",
      "         [[-1.2981e-02,  1.6705e-03,  1.2927e-02,  2.6795e-02, -2.8396e-02],\n",
      "          [ 3.3459e-02,  3.8814e-02,  4.0815e-02,  1.2954e-02, -2.6571e-02],\n",
      "          [-2.8785e-02,  5.1479e-03, -1.8889e-02, -1.0277e-02, -4.2726e-02],\n",
      "          [ 5.6475e-03,  1.8369e-02,  3.7409e-02, -5.7642e-03, -4.5623e-04],\n",
      "          [ 5.5267e-03,  4.0883e-02,  1.9995e-02,  2.2697e-02,  3.3017e-02]],\n",
      "\n",
      "         [[ 3.4499e-02,  1.8402e-02,  2.8457e-02,  3.4916e-02, -4.3865e-02],\n",
      "          [-3.8057e-02, -4.4197e-02, -1.6587e-02,  2.5361e-02,  4.3631e-02],\n",
      "          [-2.6923e-03,  2.6579e-02,  1.3922e-02,  2.1726e-03,  1.3111e-02],\n",
      "          [-1.7161e-02, -6.0403e-03,  2.6841e-02, -2.5569e-02,  4.3244e-02],\n",
      "          [-4.4006e-02,  2.2790e-02,  3.1158e-02,  1.9848e-02, -3.4478e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.5299e-02,  2.6980e-02, -2.3683e-02, -2.9629e-02,  3.3349e-02],\n",
      "          [ 2.8947e-02, -2.4055e-02,  5.9396e-03,  3.9093e-02, -2.9581e-02],\n",
      "          [-4.0768e-02,  1.6928e-02,  3.9718e-02,  2.2575e-02,  3.1460e-02],\n",
      "          [ 1.0061e-02, -3.0581e-03, -2.5958e-02, -2.3175e-02,  4.4057e-02],\n",
      "          [ 6.4247e-03,  1.2176e-02, -3.1463e-02, -2.3087e-02,  3.5514e-04]],\n",
      "\n",
      "         [[-1.3912e-02, -4.4298e-02, -1.0412e-02, -3.9127e-02,  4.2200e-02],\n",
      "          [ 1.8008e-02, -1.7010e-02, -3.8739e-02,  4.4325e-02, -1.7791e-02],\n",
      "          [ 3.6593e-02, -2.9461e-02, -3.6635e-03,  1.4364e-02, -3.8304e-02],\n",
      "          [ 5.0817e-03,  1.6326e-03,  1.3158e-02,  2.0557e-02, -2.5205e-02],\n",
      "          [-1.9261e-02, -3.0364e-02,  2.4700e-02,  3.8919e-02, -4.4172e-02]],\n",
      "\n",
      "         [[ 2.7085e-02, -1.4332e-02, -3.5458e-02, -2.8232e-02, -3.3837e-02],\n",
      "          [-2.8039e-02,  5.0111e-03, -1.9859e-02,  2.6290e-03, -9.2996e-03],\n",
      "          [-3.9681e-02,  1.5816e-02,  3.7200e-02,  1.1111e-02,  2.9330e-02],\n",
      "          [-4.3052e-02,  1.0561e-02,  3.5881e-02,  3.2420e-03,  4.4711e-02],\n",
      "          [ 1.7062e-02, -3.4994e-03, -2.2714e-03,  6.8745e-04, -7.5571e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3971e-02,  1.7817e-02,  3.8500e-02, -1.2192e-02, -4.0206e-02],\n",
      "          [ 1.7743e-02,  4.3200e-02, -1.5599e-02, -4.4536e-03,  4.0701e-02],\n",
      "          [-4.1600e-02,  2.8472e-02,  2.9640e-02, -4.0537e-02, -1.3224e-02],\n",
      "          [-3.6160e-02,  3.9857e-02,  4.1882e-02, -4.1040e-02, -6.6881e-03],\n",
      "          [-2.9331e-02, -2.7933e-02, -2.9815e-02,  4.0863e-02,  4.3758e-02]],\n",
      "\n",
      "         [[ 2.9679e-02, -2.6155e-04,  1.7701e-02, -1.2713e-02,  1.8417e-02],\n",
      "          [-3.3772e-03,  1.2428e-02,  8.7270e-03,  1.8278e-03,  2.6286e-02],\n",
      "          [-1.3490e-02,  4.7472e-03, -1.6489e-02, -2.1659e-02, -2.4125e-02],\n",
      "          [-1.3955e-02,  2.0371e-02,  1.2886e-02,  7.4039e-03,  3.5491e-02],\n",
      "          [-3.0442e-02,  1.4001e-02,  1.6524e-02, -2.2039e-02, -1.6309e-02]],\n",
      "\n",
      "         [[-4.4380e-02, -1.3657e-02,  2.6673e-04, -2.7175e-02, -1.3445e-02],\n",
      "          [-3.4625e-04,  2.6613e-04, -3.3570e-02, -2.4531e-02,  1.0613e-02],\n",
      "          [-1.4227e-02, -1.2862e-02,  1.8087e-02, -2.9096e-02, -3.5773e-02],\n",
      "          [-1.1293e-02, -1.0369e-02,  3.5842e-02, -1.0909e-02,  3.7329e-02],\n",
      "          [-1.3170e-03, -2.3646e-02,  4.4136e-02, -4.4688e-02,  3.9081e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9455e-02,  2.6179e-02, -4.0633e-02,  1.7506e-02,  1.9553e-02],\n",
      "          [-1.7208e-02,  9.8829e-03, -3.1190e-03,  4.4303e-02,  2.1542e-02],\n",
      "          [-3.3581e-02, -1.1105e-02, -3.8712e-02,  3.3120e-02,  2.4049e-02],\n",
      "          [-3.6179e-02, -3.2511e-03, -3.6473e-02,  6.2013e-03, -3.5386e-02],\n",
      "          [ 4.3681e-02, -1.9010e-04, -6.7995e-03,  1.1395e-02, -4.2485e-02]],\n",
      "\n",
      "         [[ 2.0793e-02,  1.5447e-03,  3.6208e-02, -5.6038e-03, -2.4047e-02],\n",
      "          [ 3.8653e-03,  2.5518e-02,  4.3870e-02, -2.6216e-02,  6.7740e-03],\n",
      "          [-2.4761e-02,  3.6192e-02,  2.6757e-02,  3.0431e-02, -8.9072e-03],\n",
      "          [ 4.0890e-02, -3.4159e-02,  2.5925e-02,  2.1719e-02, -4.2549e-02],\n",
      "          [-2.0186e-02, -1.9539e-02,  1.9997e-02, -4.0655e-02, -1.9505e-02]],\n",
      "\n",
      "         [[ 1.9036e-02,  1.6582e-02, -3.5188e-02,  2.7824e-05, -3.8274e-02],\n",
      "          [ 4.1949e-02, -2.2908e-02,  2.6106e-02, -3.4834e-03, -2.5108e-02],\n",
      "          [ 3.0040e-02,  2.9047e-02, -3.7205e-02,  1.5518e-02,  7.4245e-03],\n",
      "          [ 6.3157e-03, -3.2125e-02, -2.1727e-03,  2.9215e-02, -4.0367e-02],\n",
      "          [ 3.0424e-02, -3.9836e-02, -9.6026e-03,  3.3846e-02, -1.9458e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8284e-03,  2.5483e-02,  3.4191e-02, -3.4364e-02, -5.5623e-03],\n",
      "          [-2.2508e-02,  3.3620e-02, -3.3397e-02, -3.2528e-02, -1.7038e-02],\n",
      "          [ 1.3947e-03, -3.6178e-02, -3.6048e-02, -2.3110e-03,  1.0339e-02],\n",
      "          [-1.0594e-02, -1.0683e-02, -2.1641e-02, -1.1665e-02,  8.7499e-03],\n",
      "          [-3.4159e-03,  3.7459e-02, -2.1380e-02,  3.9599e-02,  1.7350e-02]],\n",
      "\n",
      "         [[ 3.7377e-03,  1.8496e-02, -4.1863e-02,  2.0240e-03, -1.2686e-02],\n",
      "          [ 2.4268e-02, -1.1415e-02, -1.6671e-02, -1.9078e-02,  4.1379e-02],\n",
      "          [ 6.0766e-03,  9.8440e-03,  1.3734e-02, -2.8718e-02, -9.1186e-03],\n",
      "          [ 2.3665e-02, -8.5737e-03,  9.9061e-04, -2.9545e-02,  2.1760e-02],\n",
      "          [ 4.1272e-02,  4.2249e-02, -3.9312e-03,  3.8413e-03,  1.0899e-02]],\n",
      "\n",
      "         [[-1.2686e-02,  2.1031e-02,  3.5995e-02, -8.1442e-03, -1.3423e-02],\n",
      "          [-3.5023e-02, -3.6406e-02,  1.3896e-02, -1.3334e-02, -1.4643e-02],\n",
      "          [-2.3096e-02,  3.8395e-02, -3.1414e-02,  1.7700e-02,  3.6275e-02],\n",
      "          [-2.2490e-02, -4.4129e-02,  3.9271e-02, -1.3130e-02, -2.2805e-03],\n",
      "          [ 1.0026e-02, -3.9385e-02, -1.1783e-02,  4.3138e-02,  2.1259e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0653e-02, -3.5554e-02,  1.1227e-02, -4.2073e-02,  2.0914e-02],\n",
      "          [-3.2507e-02, -1.5332e-02,  1.6926e-02,  1.2922e-02,  7.1809e-03],\n",
      "          [-2.0205e-02,  1.7964e-02,  4.0022e-02,  1.7293e-02, -9.7118e-04],\n",
      "          [-2.4335e-03, -4.2072e-02,  4.1253e-02, -3.2525e-02,  3.5043e-02],\n",
      "          [-2.1286e-02,  4.0847e-02,  1.0692e-02,  1.9358e-02,  3.0881e-02]],\n",
      "\n",
      "         [[ 1.6294e-02, -1.4971e-02,  2.5460e-04, -5.4573e-03, -4.4546e-02],\n",
      "          [-1.2122e-02, -2.8602e-02, -1.4345e-02,  2.1663e-02, -6.7391e-05],\n",
      "          [ 3.5451e-02,  4.3320e-02, -3.2662e-02,  7.0589e-03, -3.5447e-02],\n",
      "          [ 3.3281e-03,  5.1642e-03, -2.4120e-02,  9.3456e-03, -1.4926e-02],\n",
      "          [-5.8951e-03, -1.6300e-03,  4.4191e-02,  2.4656e-02, -8.9715e-03]],\n",
      "\n",
      "         [[ 3.7736e-03, -1.0569e-02, -2.9429e-02,  1.3954e-03, -3.2939e-02],\n",
      "          [ 2.2889e-03, -9.3718e-03, -1.2797e-02, -7.4245e-03, -1.5124e-02],\n",
      "          [-3.9046e-02, -2.4115e-03, -1.7986e-02,  2.4624e-02,  2.8539e-02],\n",
      "          [ 3.6217e-02,  2.6454e-02, -2.3148e-03, -1.8568e-02,  2.5444e-02],\n",
      "          [-4.4868e-03, -2.8804e-02,  3.2927e-02,  3.4484e-02, -5.7244e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4980e-02,  8.1141e-03, -4.2157e-02,  3.4270e-02,  6.7781e-03],\n",
      "          [ 2.2384e-03,  3.8923e-02, -1.3879e-02,  4.5648e-03,  4.6259e-03],\n",
      "          [-1.8089e-02,  1.6640e-02, -4.2039e-02,  1.6549e-02, -3.7562e-02],\n",
      "          [-7.9452e-03,  2.3177e-03,  7.3981e-03,  1.2962e-02,  1.3915e-02],\n",
      "          [-2.0637e-02,  3.9021e-02, -3.5824e-03,  3.3800e-03,  3.2585e-02]],\n",
      "\n",
      "         [[ 3.3657e-02,  1.2080e-02, -3.5999e-03,  2.0060e-02, -3.9363e-03],\n",
      "          [-2.9145e-03,  3.5429e-03, -2.2847e-03, -1.7774e-02, -2.6973e-04],\n",
      "          [ 4.3662e-02, -4.2557e-03, -7.6914e-03, -2.4345e-02, -2.5520e-02],\n",
      "          [ 1.6204e-03,  4.0455e-02, -2.2345e-02,  1.6280e-02,  2.7766e-02],\n",
      "          [-5.5652e-03,  3.2405e-02, -7.2149e-04, -9.9520e-03,  1.6097e-02]],\n",
      "\n",
      "         [[ 2.3334e-02,  2.4354e-02,  3.8524e-02, -3.9277e-02,  3.8283e-02],\n",
      "          [-3.8719e-02, -1.8969e-02,  2.5806e-02,  3.5139e-02,  4.1840e-02],\n",
      "          [ 2.0554e-02, -1.4046e-02, -2.1438e-02,  2.2487e-02,  4.1848e-02],\n",
      "          [-5.4252e-03,  4.1741e-03,  3.0892e-02,  2.5318e-03, -1.8232e-02],\n",
      "          [ 2.4703e-02, -2.2791e-02,  2.9557e-02,  4.4612e-02,  4.3168e-02]]]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0038,  0.0183,  0.0034,  0.0065,  0.0003, -0.0053, -0.0212, -0.0432,\n",
      "        -0.0012, -0.0171,  0.0343, -0.0008, -0.0225, -0.0227,  0.0429, -0.0330,\n",
      "         0.0281, -0.0412, -0.0046, -0.0234,  0.0395,  0.0344, -0.0336,  0.0378,\n",
      "         0.0021,  0.0383,  0.0368,  0.0416, -0.0351,  0.0094,  0.0111,  0.0243,\n",
      "         0.0003,  0.0172, -0.0051, -0.0103, -0.0076,  0.0381, -0.0273, -0.0438,\n",
      "        -0.0276,  0.0051,  0.0031,  0.0191, -0.0057, -0.0319, -0.0215,  0.0413,\n",
      "        -0.0385,  0.0407], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0206,  0.0204, -0.0072,  ..., -0.0190,  0.0253,  0.0172],\n",
      "        [-0.0050, -0.0091, -0.0253,  ..., -0.0257,  0.0075, -0.0152],\n",
      "        [-0.0181, -0.0170,  0.0015,  ...,  0.0015, -0.0114, -0.0142],\n",
      "        ...,\n",
      "        [-0.0146,  0.0082,  0.0313,  ..., -0.0218, -0.0147,  0.0276],\n",
      "        [ 0.0030, -0.0288, -0.0041,  ..., -0.0250,  0.0315, -0.0045],\n",
      "        [ 0.0169,  0.0016,  0.0305,  ..., -0.0154, -0.0057, -0.0063]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 2.5126e-02, -2.8897e-02,  1.2706e-02,  1.4795e-02,  2.8139e-02,\n",
      "         2.0787e-02,  1.4787e-03,  1.9443e-02, -1.6315e-02,  2.1279e-02,\n",
      "         2.5451e-02,  1.1438e-02, -2.8715e-02,  3.4964e-02, -3.3935e-02,\n",
      "         1.5225e-02, -2.9799e-02, -6.5532e-03, -2.7516e-02,  5.4560e-03,\n",
      "        -1.8867e-02, -6.2348e-03, -3.0809e-02,  5.5116e-03, -1.6242e-02,\n",
      "         1.4870e-03,  2.7954e-02, -4.6560e-03,  1.0260e-02,  3.3697e-02,\n",
      "         1.9746e-02,  2.5452e-02,  2.8695e-02,  6.2807e-03,  1.5637e-02,\n",
      "        -2.6000e-02, -2.5614e-02,  7.3817e-03, -4.6397e-03,  7.7959e-03,\n",
      "        -9.6227e-03, -2.5821e-02,  4.8811e-03, -2.9643e-02, -1.7746e-02,\n",
      "         3.1172e-02, -1.1501e-02, -3.1401e-02, -9.8621e-03, -1.6668e-02,\n",
      "         1.3922e-02,  2.7805e-02,  1.3669e-02,  3.1984e-03, -4.3351e-03,\n",
      "         3.0675e-03, -3.3748e-02,  1.4484e-02, -3.5226e-02,  5.1907e-03,\n",
      "        -2.7134e-02, -3.5318e-02, -3.2084e-02, -2.6027e-02,  3.2476e-02,\n",
      "         2.9045e-02, -7.6769e-03, -8.9386e-03, -3.5245e-03,  3.2100e-02,\n",
      "        -2.1718e-02, -6.2380e-03,  2.5769e-02,  1.9313e-02,  3.2110e-02,\n",
      "        -4.9264e-03,  2.4515e-02,  1.1887e-02,  2.6563e-03, -2.1103e-02,\n",
      "         1.3391e-02, -1.0544e-02,  1.0345e-02, -9.6566e-03, -1.3892e-03,\n",
      "         2.3914e-02, -1.9424e-02, -1.5102e-02, -1.6083e-02, -7.6927e-03,\n",
      "         6.6486e-03, -3.2399e-02,  3.0472e-02,  1.6294e-02, -3.2226e-02,\n",
      "         9.4997e-04,  1.1445e-02,  1.5506e-02,  5.9053e-03, -3.3721e-02,\n",
      "        -2.3397e-02, -1.0919e-02, -9.8083e-03,  2.1561e-02,  6.7462e-03,\n",
      "        -9.4997e-04, -2.8601e-02,  1.3639e-02,  3.4078e-02,  1.1150e-02,\n",
      "        -2.1888e-02, -4.9919e-03, -1.3364e-02, -2.7955e-02,  2.4600e-02,\n",
      "         5.9469e-04,  1.8386e-02, -5.4912e-04,  2.4723e-02, -5.7774e-03,\n",
      "         1.6903e-02,  1.3543e-02,  1.0952e-02,  1.8810e-02,  2.4791e-03,\n",
      "        -1.8169e-02, -1.1956e-02, -7.2476e-03,  1.8284e-02,  3.5354e-02,\n",
      "        -2.2654e-02,  3.5264e-03, -2.1640e-02,  1.0007e-03,  6.8315e-03,\n",
      "        -1.4418e-02, -2.2809e-02, -3.2735e-02, -2.5986e-02,  3.0335e-02,\n",
      "        -6.9808e-03, -7.9194e-04, -2.0940e-02,  3.2263e-02, -9.0704e-04,\n",
      "         1.7293e-02, -3.3928e-02, -2.6636e-02,  1.4023e-02, -1.4865e-02,\n",
      "         1.2162e-02,  5.1233e-03,  3.4854e-02,  2.7034e-02,  3.5574e-04,\n",
      "         1.9974e-02, -1.6511e-02, -2.0666e-02, -1.7977e-02,  3.4341e-02,\n",
      "         2.7170e-02, -2.8083e-02, -2.5181e-02,  1.4525e-02,  1.0434e-02,\n",
      "        -6.3150e-03,  5.5775e-04, -1.5502e-02, -2.7660e-02, -1.5505e-02,\n",
      "        -1.5696e-02,  1.5182e-02,  2.8898e-02, -2.2131e-02,  1.3292e-02,\n",
      "        -3.4507e-02,  3.0915e-02,  6.5921e-03, -1.7050e-03, -3.1867e-03,\n",
      "         1.4617e-02, -1.0489e-02,  3.0983e-02, -3.1351e-02,  7.3212e-03,\n",
      "         3.0877e-02, -9.7500e-03, -1.4100e-02, -1.5879e-02,  3.2777e-02,\n",
      "         3.3151e-02,  3.1577e-02, -9.5817e-03, -2.1624e-02, -2.6287e-02,\n",
      "        -3.4295e-02, -9.3563e-03,  1.2598e-02,  3.0903e-02,  1.0028e-02,\n",
      "         1.2495e-02,  8.6208e-04,  4.7716e-03,  3.3265e-02,  1.0511e-02,\n",
      "        -8.0583e-03,  1.4940e-02, -7.7563e-03, -3.0826e-02,  6.0250e-04,\n",
      "         1.4727e-02, -1.1955e-02, -3.1718e-02,  1.1649e-02,  6.5600e-03,\n",
      "        -1.0120e-02, -3.7807e-03,  2.5652e-02,  8.5689e-03, -7.3909e-04,\n",
      "         2.1554e-02, -1.1111e-02,  7.6579e-03, -1.0122e-02,  3.6818e-03,\n",
      "        -7.7486e-03, -1.9617e-02, -2.7657e-02, -2.8249e-02, -3.0868e-02,\n",
      "        -3.2359e-02,  9.8535e-03, -4.2860e-03, -1.3189e-02, -2.2594e-02,\n",
      "        -1.7502e-02,  2.0913e-02,  8.8997e-03, -3.3471e-02, -1.5469e-02,\n",
      "        -3.2355e-02,  2.5742e-02, -1.6177e-02, -2.6559e-02, -1.2749e-02,\n",
      "        -2.1009e-02,  2.0828e-04,  3.0113e-02, -2.1156e-02,  2.8301e-02,\n",
      "        -3.4005e-02,  2.2484e-02, -2.9418e-03, -3.5042e-02, -2.9033e-02,\n",
      "        -8.5863e-03, -2.9603e-02,  1.2811e-03, -2.2647e-02,  2.3971e-02,\n",
      "         2.5470e-02, -2.0539e-02,  1.0416e-02, -2.8707e-02,  2.3133e-02,\n",
      "         1.1753e-02,  1.7391e-04, -3.0013e-02,  6.1760e-03,  2.2636e-02,\n",
      "        -2.7843e-02, -1.8268e-02, -1.4340e-02, -5.8932e-03,  6.5126e-03,\n",
      "         3.3286e-02, -1.0704e-02,  1.9709e-02,  3.3177e-02,  1.9075e-02,\n",
      "        -1.6384e-02, -2.8111e-02,  2.5190e-02, -4.6929e-03, -2.9908e-02,\n",
      "         9.4241e-03,  3.4547e-02, -4.6423e-03, -2.2628e-02, -2.5665e-02,\n",
      "         2.9041e-02, -9.6771e-03, -2.7786e-02,  2.3654e-02, -7.7887e-03,\n",
      "        -3.2266e-03,  1.6094e-02,  2.4048e-02,  1.8706e-02,  2.6052e-02,\n",
      "        -1.9074e-02, -3.2336e-02,  2.7033e-03,  3.3855e-02,  2.0048e-02,\n",
      "         3.1581e-02,  2.3516e-02, -4.0003e-04, -7.3240e-03,  2.4539e-02,\n",
      "        -3.0443e-03,  5.3884e-03,  2.7713e-02,  3.9861e-03,  3.3238e-02,\n",
      "        -3.3657e-02,  4.3541e-03, -1.8182e-02, -1.2961e-02, -1.4636e-02,\n",
      "         1.2571e-02,  2.2299e-02, -3.3553e-02, -1.3068e-02,  2.0769e-02,\n",
      "         2.2352e-02, -2.8163e-02, -7.4915e-04,  2.5666e-02,  9.3930e-03,\n",
      "         2.2729e-02, -2.7009e-02,  1.2037e-02,  3.1745e-02,  2.5907e-02,\n",
      "         5.7750e-03, -1.7811e-02,  8.2568e-03,  1.1969e-02, -3.1579e-02,\n",
      "         3.0974e-02,  1.0966e-02, -9.9847e-03,  1.0851e-02, -2.0610e-02,\n",
      "        -5.7352e-03, -3.1402e-02, -4.5126e-03,  3.2108e-02,  2.9405e-02,\n",
      "         2.2730e-02, -6.3719e-03,  2.1187e-02, -2.9429e-03, -1.6378e-02,\n",
      "         1.3931e-02,  3.0657e-03, -1.0269e-03, -2.9338e-02, -1.2539e-02,\n",
      "         2.1606e-02,  1.3185e-03, -3.0471e-02,  1.8883e-02,  3.2225e-02,\n",
      "        -1.4202e-02, -2.7608e-03,  2.5233e-02, -2.6914e-02,  1.5788e-02,\n",
      "         2.1825e-02,  1.1111e-02,  1.9967e-02, -1.1418e-03, -9.9721e-03,\n",
      "         2.3162e-02,  1.1716e-03, -1.1904e-02,  8.4233e-04, -2.3586e-03,\n",
      "         2.5491e-02, -2.2516e-02, -1.8692e-02, -7.9945e-03, -1.1828e-02,\n",
      "        -1.6896e-04,  2.9183e-02,  7.6450e-03, -3.9140e-03,  1.7152e-02,\n",
      "         3.0398e-03,  4.3885e-04, -9.0740e-03, -1.0547e-02,  3.2165e-02,\n",
      "        -1.7140e-02, -3.5333e-02, -3.2094e-02,  5.5692e-03,  7.2289e-03,\n",
      "        -1.0321e-02,  2.5281e-02, -2.5238e-03, -2.8298e-02, -3.1654e-02,\n",
      "        -3.2139e-02,  1.4964e-03, -3.2593e-02, -2.7062e-02, -1.4390e-02,\n",
      "        -2.4555e-02,  1.4862e-02, -2.2739e-02, -2.0679e-02, -2.8742e-02,\n",
      "        -2.0487e-02, -3.3896e-02,  3.0931e-02, -4.7562e-03, -3.3386e-02,\n",
      "        -3.5314e-02, -5.7929e-03, -6.9305e-03, -2.8825e-02,  2.5724e-02,\n",
      "         5.2029e-03,  1.8238e-02,  7.8995e-03,  1.0150e-02,  1.2835e-02,\n",
      "        -4.1334e-03, -1.9637e-03, -1.3165e-02, -2.3989e-02,  2.1283e-02,\n",
      "        -1.2703e-02,  1.3439e-02, -1.3991e-02,  3.5333e-02,  3.4957e-02,\n",
      "        -3.0009e-02, -8.5867e-03,  8.2076e-05,  2.9918e-02,  3.1100e-02,\n",
      "        -2.4207e-02, -2.7648e-03, -2.2782e-02,  5.7708e-03,  4.6528e-03,\n",
      "         2.9501e-02, -1.9712e-02, -1.4293e-02, -3.3612e-03,  3.4319e-02,\n",
      "        -1.6183e-02, -1.8751e-02,  2.5112e-02, -2.9128e-02,  1.2529e-02,\n",
      "         2.4365e-02, -1.1812e-02, -6.6003e-03,  5.6386e-03,  2.6129e-02,\n",
      "        -2.8497e-02, -1.8566e-02, -2.1407e-02, -1.5857e-02, -3.1839e-03,\n",
      "        -1.2958e-02, -5.9416e-03, -2.3079e-02, -9.4493e-03, -3.2070e-02,\n",
      "        -2.2179e-02, -2.8902e-02,  1.0783e-02,  1.0685e-02, -1.2715e-02,\n",
      "         3.2429e-02, -1.9510e-02, -2.1812e-03,  2.5515e-02, -1.8019e-05,\n",
      "         1.1271e-02, -1.6056e-02, -2.5273e-02, -1.7855e-02, -3.0680e-02,\n",
      "         2.7966e-02,  3.4260e-02,  3.3841e-02, -2.0909e-02,  2.0349e-02,\n",
      "        -6.4190e-03,  1.6175e-02, -3.3746e-02, -2.3421e-02, -5.1158e-03],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0156, -0.0220,  0.0360,  ...,  0.0095,  0.0118,  0.0294],\n",
      "        [-0.0040, -0.0414, -0.0123,  ..., -0.0425,  0.0418, -0.0413],\n",
      "        [-0.0236,  0.0131,  0.0285,  ...,  0.0216,  0.0174, -0.0431],\n",
      "        ...,\n",
      "        [-0.0422,  0.0302,  0.0355,  ...,  0.0306,  0.0197,  0.0272],\n",
      "        [-0.0004,  0.0081, -0.0194,  ...,  0.0277, -0.0256,  0.0411],\n",
      "        [-0.0255, -0.0292,  0.0415,  ..., -0.0066, -0.0173,  0.0179]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0168,  0.0280,  0.0117, -0.0375,  0.0305,  0.0160,  0.0403, -0.0200,\n",
      "        -0.0326,  0.0356], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 431080\n"
     ]
    }
   ],
   "source": [
    "print(\"number of parameters:\",sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "training loss: 0.5494, acc 85.1233 \n",
      "epoch : 2\n",
      "training loss: 0.1441, acc 95.6817 \n",
      "epoch : 3\n",
      "training loss: 0.0975, acc 97.0917 \n",
      "epoch : 4\n",
      "training loss: 0.0768, acc 97.7100 \n",
      "epoch : 5\n",
      "training loss: 0.0633, acc 98.0983 \n",
      "epoch : 6\n",
      "training loss: 0.0540, acc 98.3317 \n",
      "epoch : 7\n",
      "training loss: 0.0488, acc 98.5200 \n",
      "epoch : 8\n",
      "training loss: 0.0437, acc 98.6950 \n",
      "epoch : 9\n",
      "training loss: 0.0395, acc 98.8483 \n",
      "epoch : 10\n",
      "training loss: 0.0361, acc 98.9033 \n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "running_loss_hist = []\n",
    "running_corrects_hist = []\n",
    "\n",
    "for e in range(epochs):\n",
    "  \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "  \n",
    "    for inputs, labels in train_load: \n",
    "        inputs = inputs.to(device)  \n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)  \n",
    "        loss = criterion(outputs, labels) \n",
    "    \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()  \n",
    "    \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() \n",
    "        running_corrects += torch.sum(preds == labels.data) \n",
    "\n",
    "    else:\n",
    "        with torch.no_grad(): \n",
    "      \n",
    "                    epoch_loss = running_loss/len(train_load)\n",
    "                    epoch_acc = running_corrects.float()/ len(train_load)\n",
    "                    running_loss_hist.append(epoch_loss)\n",
    "                    running_corrects_hist.append(epoch_acc)\n",
    "    \n",
    "                    print('epoch :', (e+1))\n",
    "                    print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        \"\"\"\n",
    "        init convolution and activation layers\n",
    "        Args:\n",
    "            input_size: (1,28,28)\n",
    "            num_classes: 10\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(input_size[0], 32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * 4 * 64, num_classes)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward function describes how input tensor is transformed to output tensor\n",
    "        Args:\n",
    "            x: (Nx1x28x28) tensor\n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), opts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()  \u001b[38;5;66;03m# loss function\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_dataset\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39mopts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39mtest_dataset, batch_size\u001b[38;5;241m=\u001b[39mopts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(opts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "model = CNN((1, 28, 28), 10)\n",
    "    \n",
    "opts = {\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 20,\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), opts['lr'])\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=opts['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=opts['batch_size'], shuffle=True)\n",
    "\n",
    "for epoch in range(opts['epochs']):\n",
    "    train_loss = []\n",
    "    for i, (data, labels) in tqdm_notebook(enumerate(train_loader), total=len(train_loader)):\n",
    "        # pass data through network\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    for i, (data, labels) in enumerate(test_loader):\n",
    "        # pass data through network\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss.append(loss.item())\n",
    "        test_accuracy.append((predicted == labels).sum().item() / predicted.size(0))\n",
    "    print('epoch: {}, train loss: {}, test loss: {}, test accuracy: {}'.format(epoch, np.mean(train_loss), np.mean(test_loss), np.mean(test_accuracy)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training a Classifier\n",
    "\n",
    "This is it. You have seen how to define neural networks, compute loss and make\n",
    "updates to the weights of the network.\n",
    "\n",
    "Now you might be thinking,\n",
    "\n",
    "## What about data?\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.*Tensor``.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful\n",
    "\n",
    "Specifically for vision, we have created a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "For this tutorial, we will use the CIFAR10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    ".. figure:: /_static/img/cifar10.png\n",
    "   :alt: cifar10\n",
    "\n",
    "   cifar10\n",
    "\n",
    "\n",
    "## Training an image classifier\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalize the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "### 1. Load and normalize CIFAR10\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>If running on Windows and you get a BrokenPipeError, try setting\n",
    "    the num_worker of torch.utils.data.DataLoader() to 0.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Convolutional Neural Network\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Loss function and optimizer\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the network\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly save our trained model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [here](https://pytorch.org/docs/stable/notes/serialization.html)\n",
    "for more details on saving PyTorch models.\n",
    "\n",
    "### 5. Test the network on the test data\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "The higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks way better than chance, which is 10% accuracy (randomly picking\n",
    "a class out of 10 classes).\n",
    "Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so what next?\n",
    "\n",
    "How do we run these neural networks on the GPU?\n",
    "\n",
    "## Training on GPU\n",
    "Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "\n",
    "Let's first define our device as the first visible cuda device if we have\n",
    "CUDA available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this section assumes that ``device`` is a CUDA device.\n",
    "\n",
    "Then these methods will recursively go over all modules and convert their\n",
    "parameters and buffers to CUDA tensors:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "Why don't I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is really small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "## Training on multiple GPUs\n",
    "If you want to see even more MASSIVE speedup using all of your GPUs,\n",
    "please check out :doc:`data_parallel_tutorial`.\n",
    "\n",
    "## Where do I go next?\n",
    "\n",
    "-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n",
    "-  `Train a state-of-the-art ResNet network on imagenet`_\n",
    "-  `Train a face generator using Generative Adversarial Networks`_\n",
    "-  `Train a word-level language model using Recurrent LSTM networks`_\n",
    "-  `More examples`_\n",
    "-  `More tutorials`_\n",
    "-  `Discuss PyTorch on the Forums`_\n",
    "-  `Chat with other users on Slack`_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataiter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
